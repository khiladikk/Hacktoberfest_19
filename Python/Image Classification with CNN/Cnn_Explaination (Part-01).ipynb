{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "CNN are powerful deep networks that are widely used in image related tasks like - Image Recognition, Segmenation, Computer Vision etc Input to these networks are images. Convolutional Neural networks allow computers to see, in other words, Convnets are used to recognize images by transforming the original image through layers to a class scores.\n",
    "\n",
    "<img src=\"cnn2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Another type of network?? \n",
    "\n",
    "Problem with Multilayer Perceptrons(MLP's) >>\n",
    "\n",
    "<img src=\"cnn33.jpg\">\n",
    "\n",
    "1. Overfitting due too many parameters(~millions), while working with medium-large sized images!\n",
    "2. Fail to handle variance in images - translation, rotation, illumination, size etc!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How CNN Works ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution layer>>\n",
    "\n",
    "The objective of a Conv layer is to extract features of the input volume.\n",
    "\n",
    "> Convolution layer contains various filters\n",
    "\n",
    "> Each filter extracts different kinds of features and gives 1 activation map.\n",
    "\n",
    "> Multiple activation maps are combined by stacking to form output volume \n",
    " so CNN layer takes input a volume and produces an output volume of different shape.\n",
    "\n",
    "<img src=\"cnn5.gif\">\n",
    "\n",
    "(Source : CS231n notes)\n",
    "\n",
    "When the feature is present in part of an image, the convolution operation between the filter and that part of the image results in a real number with a high value. If the feature is not present, the resulting value is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in CNN \n",
    "\n",
    "- Convolution Layer\n",
    "- Valid vs Same Convolution\n",
    "- Padding\n",
    "- Stride\n",
    "- Filters/Kernels\n",
    "- Pooling (Average/Maxpooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride\n",
    "\n",
    "Stride has the objective of producing smaller output volumes spatially. For example, if a stride=2, the filter will shift by the amount of 2 pixels as it convolves around the input volume. Normally, we set the stride in a way that the output volume is an integer and not a fraction. Common stride: 1 or 2 (Smaller strides work better in practice), uncommon stride: 3 or more.\n",
    "\n",
    "- Filters can have different size as well as movement\n",
    "- Stride defines how a filter should move across the image\n",
    "- No of pixels we skip each time is called stride\n",
    "- In our example we used a stride of (1,1) along W and H\n",
    "- You can also use a stride of (2,2) in that case the output volume will have less W and H\n",
    "\n",
    "**Input and Output Sizes**:\n",
    "(assuming 0 padding)\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "$$ n_C = n_{C_{prev}}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding \n",
    "\n",
    "Padding adds zeros around the outside of the input volume so that the convolutions end up with the same number of outputs as inputs. If we don’t use padding the information at the borders will be lost after each Conv layer, which will reduce the size of the volumes as well as the performance.\n",
    "\n",
    "- Convolution operation we have seen reduces \"H\" and \"W\" of original image\n",
    "- But sometimes we want the output image to have same size as input image\n",
    "- So we can achieve this by adding 0 value pixels(neurons) outside the original image\n",
    "- This is called Padding\n",
    "\n",
    "**Input and Output Sizes after Convolution**:\n",
    "(with padding)\n",
    "\n",
    "\n",
    "\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_C = \\text{number of filters used in the convolution}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU layer :\n",
    "\n",
    "- ReLU Layer applies an elementwise activation function max(0,x), which turns negative values to zeros (thresholding at zero). This layer does not change the size of the volume and there are no hyperparameters.\n",
    "\n",
    "<img src=\"cnn7.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers\n",
    "- Pooling is performed after Convolution Operation\n",
    "- Two types of pooling layer - Average Pooling and Max Pooling\n",
    "\n",
    "- **Max-pooling layer**: slides an ($f, f$) window over the input and stores the max value of the window in the output.\n",
    "\n",
    "- **Average-pooling layer**: slides an ($f, f$) window over the input and stores the average value of the window in the output.\n",
    "\n",
    "- It helps to reduce computation by discarding 75% of the neurons(assuming 2X2 filters with stride of 2)\n",
    "- Makes feature detectors more robust\n",
    "- No parameters for learning, only hyperparameters such as filter size and type of pooling.\n",
    "\n",
    "<img src=\"cnn4.png\">\n",
    "\n",
    "Example of a Max pooling with 2x2 filter and stride = 2. So, for each of the windows, max pooling takes the max value of the 4 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully_Connected Layer (FC):\n",
    "\n",
    "- Fully connected layers connect every neuron in one layer to every neuron in another layer. The last fully-connected layer uses a softmax activation function for classifying the generated features of the input image into various classes based on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General CNN Architecture\n",
    "\n",
    "<img src=\"cnn6.png\">\n",
    "\n",
    "[INPUT —> CONV —> RELU —> POOL —> FC —> SoftMax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referances >>\n",
    "- Stanford CS231n notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
